\section{Трекинг на основе особых точек и цвета}\label{tracking}

Данный раздел содержит описание предлагаемого алгоритма трекинга,
комбинирующего в себе два подхода: основанный на ключевых точках и основанный
на цветах. Сначала идет описание части метода, использующей точечные
особенности изображения. Оно является достаточно кратким, поскольку
рассказывает о довольно распространенном и известном подходе. Затем идет
описание части, использующей цветовую информацию. Оно является более подробным,
поскольку касается менее общеизвестного подхода и содержит некоторые
модификации. Завершается раздел описанием способа комбинирования цветового и
точечного алгоритмов.
\subsection{Трекинг на основе точечных особенностей изображения}
\label{subs:feat_tracking}
Применяемый в данной работе алгоритм трекинга с помощью точечных особенностей
представляет собой разновидность стандартного подхода "--- трекера Канаде "---
Лукаса "--- Томаси
(KLT-трекера)\cite{LucasAndKanade,TomasiAndKanade,ShiAndTomasi,PyrLK}. На
кадрах с известной позицией объекта выделяются ключевые 2D-точки (точечные
особенности) и определяются соответствующие им 3D-точки на поверхности модели.
Движение ключевых точек от кадра к кадру отслеживается с помощью вычисления
оптического потока. На кадре, для которого выполняется оценка позиции, по
известным 2D-3D соответствиям вычисляется положение объекта путем решения
задачи \PnP\cite{LepetitSurvey} с использованием RANSAC\cite{RANSAC} для
отсеивания выбросов.
\Comment{TODO: о порядке репроецирования 3D-точек, отбрасывании треков и
пересчете 3D-позиций рассказать подробнее в разделе про комбинирование.
Возможно, здесь нужно будет кратко на это сослаться.}
\subsection{Метод на основе распределения цвета}

\Comment{TODO: нужно все, что касается чужих методов и их сравнения между собой
перевести в related work без формул, а тут оставить в первую очередь описание
метода, о котором идет речь в статье.}
Метод, использующий распределение цветов, основан на построении цветовых
гистограмм. По первому изображению, на котором позиция объекта известна,
строятся гистограммы распределения цветов $H_f$ и $H_b$ для переднего плана и
для фона соответственно. Гистограммы строятся таким образом, чтобы значения в
каждом канале разбивались на 32 ячейки, поэтому в этой главе под цветом пикселя
$y$ будем понимать множество цветов, попадающих в одну ячейку гистограммы: $y
\in [0; 31]^3$. В каждую ячейку гистограммы $H_i$ записывается доля пикселей
соответствующих цветов на области $\Omega_i$ ($i = \{f, b\}$).
Процесс получения позиции на новом кадре основан на максимизации апостериорной
вероятности позиции при данном изображении и данном наборе гистограмм. Пусть
дан новый кадр и некоторая позиция $T$. Спроецируем объект на изображение с
использованием этой позиции. Получим разбиение изображения на области
$\Omega_f$ и $\Omega_b$. Тогда, как и в~\cite{Hexner2016}, вероятность того,
что $T$ является позицией объекта, можем оценить как
\begin{equation} \label{eqn:pos_prob} P(T) = \prod\limits_{x \in
\Omega}(\mathbb{P}(x \in Fg | H_f, H_b) He(\Phi(x)) + \mathbb{P}(x \in Bg|H_f,
H_b)(1 - He(\Phi(x))) \text{.} \end{equation}
% TODO: pose enhancement

Здесь $Fg$ "--- передний план, $Bg$ "--- фон, $He$ "--- сглаженная функция
Хевисайда:
\begin{equation} \label{eqn:heaviside} He(\Phi(x)) = \frac{1}{\pi} (\arctan(s *
\Phi(x)) - \frac{\pi}{2}) \text{.} \end{equation}
Так как гистограммы влияют на принадлежность точки проекции только основываясь
на её цвете, $\mathbb{P}(x \in Fg | H_f, H_b)$ может оцениваться как
$\mathbb{P}(x \in Fg | I(x) = y)$.
Обозначим

\begin{equation} \label{eqn:Pfx} \begin{array}{c} P_f(x) = \mathbb{P}(x \in Fg
| I(x) = y) \text{,} \\ P_b(x) = \mathbb{P}(x \in Bg | I(x) = y) \text{.}
\end{array} \end{equation}
Тогда, по формуле Байеса,

\begin{equation} \label{eqn:Bayes} P_f(x)= \frac{\mathbb{P}(I(x) = y | x \in
Fg) \mathbb{P}(x \in Fg)}{\mathbb{P}(I(x) = y)} \text{.} \end{equation}
Вероятность того, что точка области $\Omega$ расположена на переднем плане,
$\mathbb{P}(x \in Fg)$ можно оценить как
\begin{equation} \label{eqn:P_x_Fg} \mathbb{P}(x \in Fg) = \frac{\eta_f}{\eta_f
+ \eta_b} \text{.} \end{equation}
$ \eta_f = \sum\limits_{x \in \Omega}He(\Phi(x)) $ "--- доля точек переднего
плана на $\Omega$,
$ \eta_b = \sum\limits_{x \in \Omega}(1 - He(\Phi(x))) $ "--- доля точек фона.
$\mathbb{P}(I(x) = y)$ расписывается по формуле полной вероятности:

\begin{equation} \label{eqn:P_Ix_y} \mathbb{P}(I(x) = y) = \mathbb{P}(I(x) = y
\mid x \in Fg) \mathbb{P}(x \in Fg) + \mathbb{P}(I(x) = y \mid x \in Bg)
\mathbb{P}(x \in Bg) \text{.} \end{equation}
Вероятность появления точки цвета $y$ на переднем плане $\mathbb{P}(I(x) = y
\mid x \in Fg)$ хранится в гистограмме для переднего плана изображения:
\begin{equation} \label{eqn:P_Ix_y_x_Fg} \mathbb{P}(I(x) = y \mid x \in Fg) =
H_f(y) \text{.} \end{equation}
Из
формул~\ref{eqn:Bayes},~\ref{eqn:P_x_Fg},~\ref{eqn:P_Ix_y},~\ref{eqn:P_Ix_y_x_Fg},
\begin{equation} \label{eqn:P_x_Fg_y} P_f(x)= \frac{H_f(y)\eta_f}{H_f(y)\eta_f
+ H_b(y)\eta_b} \end{equation}
и, аналогично,

\begin{equation} \label{eqn:P_x_Bg_y} P_b(x) = \frac{H_b(y)\eta_f}{H_f(y)\eta_f
+ H_b(y)\eta_b} \text{.} \end{equation}
Далее функция ошибки получается логарифмированием и взятием с минусом
формулы~\ref{eqn:pos_prob}:
\begin{equation} \label{err_func} E(\xi) = \sum\limits_{x \in \Omega}
\log(He(\Phi(x))P_f(x) + (1 - He(\Phi(x)))P_b(x)) \text{.} \end{equation}
После получения новой позиции на каждом следующем кадре строятся новые
гистограммы, которые взвешенно суммируются со старыми:
\begin{equation} \begin{array}{c} H_{f} = \alpha_f H_{f}^{new} + (1 - \alpha_f)
H_f^{old} \\ H_{b} = \alpha_b H_{b}^{new} + (1 - \alpha_b) H_b^{old} \text{,}
\end{array} \end{equation}
где $\alpha_f = 0.1, \alpha_b = 0.2$ - коэффициенты <<забывания>>.

Позиция объекта получается минимизацией функции ошибки~\ref{err_func}.
Оптимизация проводится методом последовательного квадратичного
программирования(SLSQP)~\cite{SLSQP}. Градиент вычисляется аналитически. Вывод
формулы градиента можно найти в~\cite{Tjaden2018}. Ширина области, на которой
проводится оптимизация, составляет $0.4$ диаметра объекта для параметров
переноса и $1$ радиан для параметров поворота. При импорте модели она
масштабируется так, чтобы её диаметр равнялся $5$, чтобы масштаб объекта не
влиял на соотношение между осями поворота и переноса.
\Comment{Про оптимизацию на пирамиде не сказано. В реализации пирамида сейчас
тоже не используется}
\Comment{Про цветовые пространства здесь не говорится. Это уже обработка
входных изображений, и она даёт значимое преимущество только на отдельном
цветовом методе. На комбинированном общий результат слабо отличается }
\subsubsection*{Определение гистограммы по точке} В формулах~\ref{eqn:P_x_Fg_y}
и~\ref{eqn:P_x_Bg_y} используются значения в гистограммах $H_f$ и $H_b$ для
данного цвета $y$. При этом, как уже было сказано, в ходе трекинга строится не
одна пара гистограмм, а несколько. В нашей реализации поддерживаются 32 пары
гистограмм: $\{{H_f}_i, {H_b}_i\}_{i = 1}^{32}$. Для каждой точки $x$ при
вычислении $P_f(x)$ и $P_b(x)$ по формулам~\ref{eqn:P_x_Fg_y}
и~\ref{eqn:P_x_Bg_y} выбирается одна из этих пар.
В качестве области $\Omega$, на которой идёт подсчёт функции ошибки, выступает
полоса вокруг контура ширины $2r$ (в нашей реализации $r = 40$). Таким образом,
нужно выбрать пару гистограмм для каждой точки этой полосы. Сама полоса
разбивается на несколько областей по той паре гистограмм, которая вэтой области
используется. Эти области должны, по возможности, содержать примерно равное
количество точек переднего плана и фона, то есть внутренней и внешней частей
полосы. Поэтому локальные области строятся так, чтобы контур проходил по
середине области. Область точки на полосе совпадает в нашем решении с областью
ближайшей к ней точки на контуре.
Таким образом, достаточно разбить на области точки контура. Для этого мы
разбиваем на несколько участков поверхность трёхмерной модели объекта: объект
помещается в центр единичной сферы, а сама сфера разбивается на32 равные по
площади части по зенитным и азимутным углам. Каждую точку объекта можно
отнормировать, чтобы она попала на поверхность сферы, и таким образом поделить
на области поверхность объекта. Проекция объекта позволяет поделить на области
контур.
Такое разделение объекта неизменно между кадрами, поэтому цветовую информацию
вгистограммах можно накапливать в ходе трекинга. Данные в гистограммах
${H_f}_i$ будет при этом соответствовать распределению цветов на определённых
областях объекта, а данные в гистограммах ${H_b}_i$ "---распределению цветов на
фоне вокруг областей. Количество гистограмм при этом относительно небольшое (по
сравнению с хранениемпары гистограмм для каждой вершины объекта) и можно
обновлять все те, области которых попали на контур.
На локальные области разделяется объект целиком. Очевидно, что на отдельном
кадре только часть областей будут спроецированы на контур и поучаствуют в
вычислении функции ошибки. Поэтому информация в некоторых гистограммах может не
набираться на протяжении большого количества кадров. После поворота объекта
такие области могут нам понадобиться, но информации в ихгистограммах не будет.
Для решения этой проблемы ведётся учёт <<опыта>> локальных гистограмм и
заводится одна глобальная гистограмма.
Если опыт $s_{local}$ гистограммы $H_{local}$ меньше некоторого порога
$s_{suff}$, то для точек соответствующей области $H_f(y)$ вычисляется как
взвешенная суммой ${H_f}_{local}(y)$ и ${H_f}_{global}(y)$:
\begin{equation} \label{eqn:histo_skill} \begin{array}{c} H_f(y) =
\frac{s_{local} {H_f}_{local} + (s_{suff} - s_{local})
{H_f}_{global}}{s_{suff}} \\ H_b(y) = \frac{s_{local} {H_b}_{local} + (s_{suff}
- s_{local}) {H_b}_{global}}{s_{suff}} \text{.} \end{array} \end{equation}
Порог $s_{suff}$ выбирается как среднее значение опыта по всем локальным
гистограммам. Опыт локальной гистограммы оценивается как общее количество
пикселей, попавших когда-либо в область гистограммы. Чтобы значение опыта
соответствовало уровню знаний о последних кадрах, на каждом кадре его значение
домножается на коэффициент, меньший единицы:
\begin{equation} s_{local} = \alpha_f s_{local}^{new} + (1 - \alpha_f)
s_{local}^{old} \text{.} \end{equation}
\Comment{TODO: описать то, как выбираются гистограммы.}

\subsection{Комбинирование методов}

\Comment{Скорее всего имеет смысл оставить тот вариант, который лучше
работает}\subsubsection{Последовательное применение алгоритмов}
\Comment{В чем суть комбинирования, просто поиск исходной позиции ключевыми
точками? Не только: еще и правильное согласование новой позиции и ключевых
точек. Оно заключает в себе: (1) репроецирование новых точек уже из новой
позиции, пересчет старых точек и отбрасывание точек с невидимых граней можно
тоже сюда же записать.}
Первый способ скрещивания алгоритмов заключается в последовательном их
применении и инициализации одного метода другим. Вычисление цветовой функции
ошибки~\ref{err_func} вместе с определением локальной области для каждой точки
и вычисление градиента занимает достаточно много времени. Поэтому для скорости
трекинга важно сократить количество итераций, за которое сходится оптимизация
функции. Этого можно достичь хорошей инициализацией оптимизации, близкой к
глобальному минимуму. В этом методе роль такой оптимизации играет алгоритм
ключевых точек.

Позиции объекта на видео определяются последовательно, от кадра к кадру. Введём
обозначения:
$F_{feat}(I)$ -- результат работы алгоритма ключевых точек на изображении $I$;
$F_{color}(T, I)$ -- результат работы цветового алгоритма на изображении $I$
при инициализации его позицией $T$;
$E_{color}(T)$ -- функция энергии цветового алгоритма от позиции $T$.

Тогда при обработке $i$-ого кадра проводится следующая последовательность
действий:
\begin{enumerate} \item Чтение изображения $I_i$ \item Вычиление позиции
алгоритмом ключевых точек: $T_{feat}^{(i)} = F_{feat}(I_i)$ \item Уточнение
позиции цветовым методом: $T^{(i)} = F_{color}(T_{feat}, I_i)$ \item Вычисление
3D-позиций, соответствующих ключевым особенностям, с использованием позиции
$T^{(i)}$ \end{enumerate}
После получения изображения проиходит вычисление позиции $T_{feat}$ алгоритмом
ключевых точек, описанным в главе~\ref{subs:feat_tracking}. Чаще всего эта
позиция близка к глобальному минимуму функции энергии цветового алгоритма, но
если метод ключевых точек отработал плохо (например из-за смазанности
изображения), то эта позиция может оказаться далеко от оптимума, и из-за этого
цветовой алгоритм может не сойтись. Чтобы избежать таких случаев, предусмотрен
альтернативный способ инициализации позиции.
Наиболее естественный способ инициализировать алгоритм трекинга при отсутствии
специального метода инициализации -- это взять позицию с предыдущего кадра. Но
очень часто неправильная работа трекинга на ключевых точках вызвана
смазанностью при быстром движении объекта. Чтобы учесть это движение, мы
вычисляем альтернативную позицию экстраполяцией движения с предыдущих кадров:
\begin{equation} \label{eqn:extrapolation} T^{(i)}_{ex} = \Delta T T^{(i - 1)}
= T^{(i - 1)}(T^{(i - 2)})^{-1} T^{(i - 1)} \text{.} \end{equation}
Эта позиция выбирается, если функция энергии цветового алгоритма на ней будет
меньше.
\begin{equation} \label{eqn:init_selection} T_{color \, init} =
argmin(E_{color}(T_{feat}), E_{color}(T_{ex})) \end{equation}
\subsubsection*{Согласование алгоритма ключевых точек с цветовым алгоритмом}
Позиция $T_{color}^{(i)}$, полученная цветовым методом, считается уточнённой по
сравнению с позицией $T_{feat}^{(i)}$. Поэтому она может быть использована,
чтобы скорректировать метод ключевых точек.
Позиция $T_{color}^{(i)}$ используется для того, чтобы получить 3D-прообразы
ключевых точек, обнаруженных впервые, для которых прообразы ещё не были
вычислены. При этом запоминается тот полигон, на котором лежит прообраз. Кроме
того, для точек, наблюдавшихся на предыдущих кадрах, 3D-позиция также
пересчитывается заново с использованием $T_{color}^{(i)}$. Она будет
использоваться в дальнейшем вместо старой 3D-позиции в случае, если окажется
точнее неё.
Точность 3D-позиции определяется ошибками её репроекции на всех кадрах, где
отслеживалась соответствующая ключевая точка. Пусть $x_{old}$ "--- старая
3D-позиция, а $x_{new}$ "--- новая. Пусть также ключевая точка была
сдетектирована на изображениях начиная с $I_k$ до текущего кадра $I_l$, и её
2D-позициями на этих кадрах были $u_k ... u_l$ соответственно. Тогда суммарной
ошибкой репроекции 3D-точки $x$ будет
\begin{equation} \label{eqn:sum_reproj} \homv{e}(\homv{x}) = \sum\limits_{i =
k}^l \| \homv{u_i} - \CamIntr \cdot [\RotMat_i \mid \TrVec_i] \cdot \homv{x} \|
\end{equation}
Старая позиция заменяется на новую, если $e(x_{new}) < e(x_{old})$. Так
цветовой трекинг позволяет уточнить 3D-прообразы ключевых точек, тем самым
делая трекинг на ключевых точках более устойчивым.
Кроме того, с помощью уточнённой позиции проводится фильтрация выбросов:
исключаются из рассмотрения те 2D-3D-соответствия, для которых ошибка
репроекции из уточнённой позиции больше определённого порога. Также удаляются
точки, которые не попадают на передний план, то есть не лежат на проекции
объекта. Если некоторый полигон не виден на переднем плане, то точки, лежащие
на нём, считаются невидимыми и тоже далее не рассматриваются. Таким образом,
уточнение позиции цветовым трекингом позволяет отфильтровать часть 2D-3D
соответствий, не согласующихся с позицией.
\Comment{Дальше идёт описание старого метода обновления 3D-позиций}

Для каждой отслеживаемой ключевой особенности известна её 3D-позиция на
объекте. Для ключевых особенностей, которые впервые появились на текущем кадре,
требуется эту позицию найти. Так как матрица трансформации, полученная цветовым
алгоритмом, считается уточнением матрицы, полученной алгоритмом ключевых точек,
именно она используется для восстановления 3D-позиций.
\Comment{TODO: процесс восстановления 3D-позиций?}

Для точечных особенностей, которые присутствовали и на предыдущих кадрах,
3D-позиция на объекте известна. Однако то положение объекта, на котором она
была вычислена, могло оказаться неверным, и тогда 3D-позиция точки также
вычислено неправильно. Эта ошибка сохраняется в течение всего времени, пока
данная точечная особенность отслеживается. Чтобы уточнить такие 3D-точки, все
они пересчитываются на новом кадре, и если новая позиция оказалась лучше, то
она заменяет старую.
Чтобы определить, какая позиция лучше, нужно оценить ошибку репроекции для
каждой позиции. Но ошибка репроекции будет нулевой для кадра, по которому
позиция вычислена, поэтому нужно выбрать какой-то кадр, на котором обе ошибки
будут отличны от нуля. Вопрос об обновлении позиции откладывается до следующего
кадра, и решается уже по репроекции на нём.
Пусть $T_{old}$ - трансформация, на которой была вычислена позиция $X_{old}$,
$T_{new}$ - трансформация, на которой была вычислена позиция $X_{new}$, $new >
old$.
Пусть $x_0$ - позиция точечной особенности на изображении $new + 1$. 

Тогда $x_{old} = \pi (K (T_{new + 1})_{3 \times 4} X_{old})$

$x_{new} = \pi (K (T_{new + 1})_{3 \times 4} X_{new})$

$e_{old} = \| x_{old} - x_0 \|$

$e_{new} = \| x_{new} - x_0 \|$

При $e_{new} < e_{old}$ позиция $X_{old}$ заменяется на $X_{new}$.
